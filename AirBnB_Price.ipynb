{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AirBnB Price.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RRO4PSpTxwcQ",
        "E23AUiAZoFDJ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8SX62bL8dyp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9uHhwqTktd3"
      },
      "source": [
        "#Data Upload and Viewing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avPZ970bO1hK"
      },
      "source": [
        "# load airbnb data\n",
        "gz = pd.read_csv('http://data.insideairbnb.com/united-states/ca/los-angeles/2021-04-07/data/listings.csv.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJaTMEeiPApf"
      },
      "source": [
        "print(gz.shape)\n",
        "gz.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yASVdaQ-hPYX"
      },
      "source": [
        "# remove unnecessary columns\n",
        "cols = gz.columns\n",
        "gz.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdqBJzquhqQj"
      },
      "source": [
        "# create a list of the columns to save\n",
        "save = [5,6,27,29,30,35,36, 40,41]\n",
        "cols_to_save = []\n",
        "\n",
        "for i in save:\n",
        "  cols_to_save.append(cols[i])\n",
        "\n",
        "print(type(cols_to_save[0]))\n",
        "\n",
        "cols_to_save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23XoXtXIq9P6"
      },
      "source": [
        "# create a new dataframe with only the needed columns\n",
        "df = gz[cols_to_save].copy()\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2mzvJb_f2aB"
      },
      "source": [
        "# check data types for all columns\n",
        "for i in df.columns:\n",
        "  des = type(df[i][1])\n",
        "  print(i)\n",
        "  print(des)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqWezrQdvZHv"
      },
      "source": [
        "# Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxzPOfiHsz8b"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMvg3lITvJsn"
      },
      "source": [
        "# fill null values\n",
        "df['description'] = df['description'].fillna(\"None\")\n",
        "df['neighborhood_overview'] = df['neighborhood_overview'].fillna(\"None\")\n",
        "df['bathrooms_text'] = df['bathrooms_text'].fillna(\"1\")\n",
        "df['bedrooms'] = df['bedrooms'].fillna(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_P0C4W0vC3o"
      },
      "source": [
        "# see if I missed any\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "759ty4-aXH_C"
      },
      "source": [
        "import re\n",
        "def fix_bathroom(text):\n",
        "  \"\"\"\n",
        "  Removes anything that is not a number\n",
        "  Converts and returns the remaining number from a str to float\n",
        "  \"\"\"\n",
        "  text = text.lower()\n",
        "\n",
        "  if text[-9:] == 'half-bath':\n",
        "    baths = float('0.5')\n",
        "  else:\n",
        "    baths = float(re.sub(r'[^0-9\\.]', '', text))\n",
        "\n",
        "  return baths\n",
        "\n",
        "def to_float(num):\n",
        "  return(float(num))\n",
        "\n",
        "\n",
        "def fix_price(price_str):\n",
        "  \"\"\"\n",
        "  convert price column from string to int\n",
        "  \"\"\"\n",
        "\n",
        "  price = re.sub(r'[^0-9]', '', price_str)\n",
        "  price = price[:-2]\n",
        "\n",
        "  return int(price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcN0fkWMXUWC"
      },
      "source": [
        "# adjust columns to appropriate data format\n",
        "df['bathrooms'] = df['bathrooms_text'].apply(fix_bathroom)\n",
        "df['minimum_nights'] = df['minimum_nights'].apply(to_float)\n",
        "df['target'] = gz['price'].apply(fix_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm48O7P1T30N"
      },
      "source": [
        "# remove outliers\n",
        "df = df[(df['target'] >= 25) & (df['target'] <= 2000) & \n",
        "        (df['bathrooms'] >=1) & (df['bathrooms'] < 4) &\n",
        "        (df['bedrooms'] >= 1) & (df['bedrooms'] <= 4) &\n",
        "        (df['minimum_nights']>=1) & (df['minimum_nights']<=30)]\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_pkPQFvcktS"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_h2bxI3z2Ix"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLfNssuxzu2V"
      },
      "source": [
        "df.drop(columns = ['description', 'neighborhood_overview', 'bathrooms_text'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTZktRPJnBz8"
      },
      "source": [
        "df['minimum_nights'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0kbRo2Y_frg"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq1WgwUtXkGl"
      },
      "source": [
        "X = df.drop(columns=['target','latitude','longitude', 'neighbourhood_cleansed'])\n",
        "y = df['target']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afjOWhog0e75"
      },
      "source": [
        "!pip install category_encoders==2.*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0TCVVDkzivK"
      },
      "source": [
        "# one hot encode\n",
        "import category_encoders as ce\n",
        "\n",
        "encoder = ce.OneHotEncoder(use_cat_names = True)\n",
        "\n",
        "X = encoder.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB7mKAJTUmFu"
      },
      "source": [
        "X.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6yckqJZVlHW"
      },
      "source": [
        "\n",
        "\n",
        "# # # define base model\n",
        "# def baseline_model():\n",
        "\n",
        "#   # create model\n",
        "#   model = Sequential()\n",
        "#   model.add(Dense(5, input_dim=3, kernel_initializer='normal', activation='relu'))\n",
        "#   model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
        "#   model.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "#   # Compile model\n",
        "#   model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "#   return model\n",
        "\n",
        "# # evaluate model with standardized dataset\n",
        "# estimators = []\n",
        "# estimators.append(('standardize', StandardScaler()))\n",
        "# estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=10, batch_size=5, verbose=0)))\n",
        "# pipeline = Pipeline(estimators)\n",
        "# kfold = KFold(n_splits=5)\n",
        "# results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "# print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTMqbzYA1lI-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cvyYjDSn2dl"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "def create_model():\n",
        "\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(5, input_dim=3, kernel_initializer='normal', activation='relu'))\n",
        "  model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
        "  model.add(Dense(1, kernel_initializer='normal'))\n",
        "  # Compile model\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "  return model\n",
        "\n",
        "# # evaluate model with standardized dataset\n",
        "# estimators = []\n",
        "# estimators.append(('standardize', StandardScaler()))\n",
        "# estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
        "# pipeline = Pipeline(estimators)\n",
        "# kfold = KFold(n_splits=5)\n",
        "# results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "# print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fAUY6UL1_me"
      },
      "source": [
        "model = create_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1LjN7US5b31"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "# from keras.wrappers.scikit_learn import KerasRegressor\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "# from sklearn.model_selection import KFold\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.pipeline import Pipeline\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(5, input_dim=4, kernel_initializer='normal', activation='relu'))\n",
        "model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
        "model.add(Dense(1, kernel_initializer='normal'))\n",
        "# Compile model\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI20GdO8KK4F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8NRHQ836Rq1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "     X, y, test_size=0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao804WVR6lc_"
      },
      "source": [
        "type(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buhmB2ne2LkO"
      },
      "source": [
        "model.fit(X, y,\n",
        "          epochs = 122,\n",
        "          batch_size=16,\n",
        "          validation_data=(X_test, y_test)\n",
        "          # metric='accuracy'\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ellBB-P4xHX"
      },
      "source": [
        "y[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAG1vsGAvl_H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd-c5ZdR7N1z"
      },
      "source": [
        "X.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl9x3DkKMype"
      },
      "source": [
        "model.predict([[2,30,730,2]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wkw1Vfg4m1D"
      },
      "source": [
        "model.predict([[4, 30, 1, 2]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om82IUGVs3Kr"
      },
      "source": [
        "# zip the model\n",
        "!zip -r ./nn.zip ./nn_model/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PreHfeD8sOeo"
      },
      "source": [
        "# download to local machine\n",
        "from google.colab import files\n",
        "files.download(\"./nn.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qtm3ynG8uEmt"
      },
      "source": [
        "# test uploading saved model\n",
        "from tensorflow import keras\n",
        "model = keras.models.load_model('./nn_model')\n",
        "\n",
        "prediction = model.predict([[2,30,730,2]])\n",
        "prediction[0][0].round()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRO4PSpTxwcQ"
      },
      "source": [
        "#Natural Language Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UHYtBxJxzQc"
      },
      "source": [
        "# Start NLP \n",
        "from collections import Counter\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# NLP Libraries\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb8VTqa4x1LO"
      },
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG8Oi6Gzx9UU"
      },
      "source": [
        "# Initialize spacy model & tokenizer\n",
        "\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "tokenizer = Tokenizer(nlp.vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn21F_uiyUg0"
      },
      "source": [
        "# Create tokenize function\n",
        "\n",
        "def tokenize(text):\n",
        "    \n",
        "    tokens = re.sub(r'[^a-zA-Z ^0-9]', ',', text)\n",
        "    tokens = tokens.lower().replace(',', ' ')\n",
        "    tokens = tokens.split()\n",
        "    \n",
        "    return tokens\n",
        "\n",
        "def fix_bathroom(text):\n",
        "  \"\"\"\n",
        "  Removes anything that is not a number\n",
        "  Converts and returns the remaining number from a str to float\n",
        "  \"\"\"\n",
        "  text = text.lower()\n",
        "\n",
        "  if text[-9:] == 'half-bath':\n",
        "    baths = float('0.5')\n",
        "  else:\n",
        "    baths = float(re.sub(r'[^0-9\\.]', '', text))\n",
        "\n",
        "  return baths\n",
        "\n",
        "\n",
        "def fix_price(price_str):\n",
        "  \"\"\"\n",
        "  convert price column from string to int\n",
        "  \"\"\"\n",
        "\n",
        "  price = re.sub(r'[^0-9]', '', price_str)\n",
        "  price = price[:-2]\n",
        "\n",
        "  return int(price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3A71F2h96RH"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEWi25dMaWaV"
      },
      "source": [
        "# convert str prices to int prices\n",
        "gz['target'] = gz['price'].apply(fix_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVhw6W4PFF3i"
      },
      "source": [
        "token_cols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAaAmxm2FNfh"
      },
      "source": [
        "type(df['bathrooms_text'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFZaajTXF8-u"
      },
      "source": [
        "df['bathrooms']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MEsjoMryY4c"
      },
      "source": [
        "# tokenize dataframe\n",
        "token_cols = df.columns\n",
        "\n",
        "# remove numerical columns\n",
        "token_cols = token_cols.drop(['latitude','bedrooms','longitude','bathrooms', 'minimum_nights'])\n",
        "\n",
        "token_cols\n",
        "for i in token_cols:\n",
        "  if i == 'bathrooms_text':\n",
        "    # df['bathrooms'] = df[i].apply(fix_bathroom)\n",
        "    g=1+1\n",
        "  else:\n",
        "    df[i+\"_token\"] = df[i].apply(tokenize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khiUonNHxf_A"
      },
      "source": [
        "df[['bedrooms', 'bathrooms', 'latitude', 'longitude']].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA3fw_N4xf_C"
      },
      "source": [
        "# remove outliers\n",
        "df['target'] = gz['target']\n",
        "# df = df[(df['target'] >= 25) & (df['target'] <= 2000) \n",
        "#       & (df['bathrooms'] <= 4) & (df['bathrooms'] >= 1)]\n",
        "#       # (df['bedrooms'] <= 4) & (df['bedrooms'] >= 1)]\n",
        "\n",
        "df = df[(df['target'] >= 25) & (df['target'] <= 2000) & \n",
        "        (df['bathrooms'] >=1) & (df['bathrooms'] < 4) &\n",
        "        (df['bedrooms'] >= 1) & (df['bedrooms'] <= 4)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTSgwe6eIMZ6"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuhz8fbbJtin"
      },
      "source": [
        "# Counter Function - takes a corpus of document and returns dataframe of word counts\n",
        "\n",
        "from collections import Counter\n",
        " \n",
        "word_counts = Counter()\n",
        "\n",
        "def count(docs):\n",
        "\n",
        "        word_counts = Counter()\n",
        "        appears_in = Counter()\n",
        "        \n",
        "        total_docs = len(docs)\n",
        "\n",
        "        for doc in docs:\n",
        "            word_counts.update(doc)\n",
        "            appears_in.update(set(doc))\n",
        "\n",
        "        temp = zip(word_counts.keys(), word_counts.values())\n",
        "        \n",
        "        wc = pd.DataFrame(list(temp), columns = ['word', 'count'])\n",
        "\n",
        "        wc['rank'] = wc['count'].rank(method='first', ascending=False)\n",
        "        total = wc['count'].sum()\n",
        "\n",
        "        wc['pct_total'] = wc['count'].apply(lambda x: x / total)\n",
        "        \n",
        "        wc = wc.sort_values(by='rank')\n",
        "        wc['cul_pct_total'] = wc['pct_total'].cumsum()\n",
        "\n",
        "        t2 = zip(appears_in.keys(), appears_in.values())\n",
        "        ac = pd.DataFrame(t2, columns=['word', 'appears_in'])\n",
        "        wc = ac.merge(wc, on='word')\n",
        "\n",
        "        wc['appears_in_pct'] = wc['appears_in'].apply(lambda x: x / total_docs)\n",
        "        \n",
        "        return wc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoxmTjpGJzLP"
      },
      "source": [
        "wc_neighborhood = count(df['neighbourhood_cleansed_token'])\n",
        "\n",
        "wc_neighborhood.sort_values(by='rank')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBf7J8-tJ6Ls"
      },
      "source": [
        "wc_neighborhood.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "470lFlCQKFCO"
      },
      "source": [
        "#Cumulative Distribution Plot\n",
        "\n",
        "sns.lineplot(x='rank', y='cul_pct_total', data=wc_neighborhood);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usoayWrGKHCv"
      },
      "source": [
        "# inspect some descriptions\n",
        "\n",
        "df['description'].iloc[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km_FyRiuzYd9"
      },
      "source": [
        "df['description'].iloc[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnFU9H096bDr"
      },
      "source": [
        "df['description'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPpfsHq4x4_9"
      },
      "source": [
        "def clean(text):\n",
        "  text = (text\n",
        "    .str.replace('<br /><br />',' ')\n",
        "    .str.replace('<b>',' ')\n",
        "    .str.replace('</b><br />',' ')\n",
        "    # .str.replace('</b><br />',' ')\n",
        "    .str.replace('*','')\n",
        "  )\n",
        "\n",
        "  return text\n",
        "\n",
        "def clean_description(text):\n",
        "\n",
        "  cleaned = re.sub(r'[^a-zA-Z]', ',', text)\n",
        "  cleaned = cleaned.lower().replace(',', ' ')\n",
        "\n",
        "  return cleaned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJSJgOR92uyy"
      },
      "source": [
        "df['cleaned_desc'] = df['description'].apply(clean_description)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5vX3TUWy4wx"
      },
      "source": [
        "# inspect cleaned descriptions and look for stop words\n",
        "df['cleaned_desc'].iloc[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnyn6px60CGH"
      },
      "source": [
        "# Vectorization\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Instantiate Vectorizer\n",
        "tfidf = TfidfVectorizer(stop_words='english', \n",
        "                        max_features=5000)\n",
        "\n",
        "# Create a vocabulary and tf-idf score per description\n",
        "dtm = tfidf.fit_transform(df['cleaned_desc'])\n",
        "\n",
        "# Get feature names to use as dataframe column headers\n",
        "general_dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
        "\n",
        "general_dtm.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHBuhiNiwzYP"
      },
      "source": [
        "general_dtm.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBtwPzJIDxKj"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E23AUiAZoFDJ"
      },
      "source": [
        "#Seasons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaJZDYWv1fZp"
      },
      "source": [
        "cal = pd.read_csv('http://data.insideairbnb.com/united-states/ca/los-angeles/2021-04-07/data/calendar.csv.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngv8DsT83Dpz"
      },
      "source": [
        "print(cal.shape)\n",
        "cal.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2LzmnDo8q7G"
      },
      "source": [
        "cal[cal['listing_id']==35922]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf4nO0duWFs9"
      },
      "source": [
        "def date_to_season(date):\n",
        "  \"\"\"\n",
        "  Takes the string of date and returns what season it is in.\n",
        "  \"\"\"\n",
        "\n",
        "  season = ['Winter', 'Spring', 'Summer', 'Fall']\n",
        "  date_num = int(date[5:7])\n",
        "  # print(date_num)\n",
        "\n",
        "\n",
        "  if date_num <=2 or date_num ==12:\n",
        "    return season[0]\n",
        "\n",
        "  elif date_num<=5:\n",
        "    return season[1]\n",
        "\n",
        "  elif date_num<=8:\n",
        "    return season[2]\n",
        "\n",
        "  else:\n",
        "    return season[3]\n",
        "\n",
        "  return season[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6wg4vcwX1Lk"
      },
      "source": [
        "date_to_season(cal['date'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ia0ganbZsaI"
      },
      "source": [
        "cal.drop(labels = 'Season', axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsuODS1jYcK3"
      },
      "source": [
        "cal['Season'] = cal['date'].apply(date_to_season)\n",
        "cal.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsZ1L6VFZqYK"
      },
      "source": [
        "listed = cal.listing_id.unique()\n",
        "len(listed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF_Ntnapahdk"
      },
      "source": [
        "temp = cal[cal['listing_id']==35922]\n",
        "temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1ufzewsbRQk"
      },
      "source": [
        "seasons = temp.Season.unique()\n",
        "season_str = np.array2string(seasons)\n",
        "type(season_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoYkqfEBgxXd"
      },
      "source": [
        "new_season = list()\n",
        "\n",
        "new_season.append(season_str)\n",
        "\n",
        "new_season"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xUrvx4uhBtl"
      },
      "source": [
        "def define_seasons(data):\n",
        "  \"\"\"\n",
        "  takes the dataframe and changes the \n",
        "  \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}